{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-NLP_Part1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlaFalaki/workshop-materials/blob/main/01-NLP_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Welcome to* **\"Practical Deep Learning\"** *workshop!*\n",
        "\n",
        "My name is **Ala Alam Falaki** *(Ph.D. Candidate @ UofW)*\n",
        "\n",
        "Research Interest:\n",
        "\n",
        "\n",
        "\n",
        "*   Natural Language Processing\n",
        "*   Generative Models\n",
        "*   Automatic Text Summarization\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5eh22jn3utV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚠️ The matterials are available on my [Github account](https://github.com/AlaFalaki/workshop-materials). You can open notebooks in the Google Colab environment and easily run them."
      ],
      "metadata": {
        "id": "0_MVT-kVwqFj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9Kvf_a4GVg1"
      },
      "source": [
        "# How to use Google Colab?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWKaVGKGGbEm"
      },
      "source": [
        "> A quick introduction on Google Colab environment.\n",
        ">\n",
        "> There are two types of cells:\n",
        "> *   Text\n",
        "> *   Code \n",
        "> \n",
        "> You can run each cell by pressing on the ▶️ button at its left side, or press \"Command+Enter\" (\"Ctrl+Enter\" for Windows).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhD9BJikGVQf",
        "outputId": "dd194a3e-cdfe-41aa-b0b7-7d3b14acaffe"
      },
      "source": [
        "a = 2\n",
        "b = 2\n",
        "\n",
        "print( a + b )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZh85AWrwVuS"
      },
      "source": [
        "> And, you have access to free GPU for ~12 hours per day. <br />\n",
        "> From the top menu, select \"Runtime > Change Runtime Type\" and you can select from 3 options: <br />\n",
        "> 1. None: Run your codes on CPU\n",
        "> 2. GPU\n",
        "> 3. TPU\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86WQwYW_HMfi"
      },
      "source": [
        "> You can also call Linux command in the code cells by putting a \"!\" before them. It is most useful because we do not have access to terminal in Free version, and by using this approach we can install/update packages that are not available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RDadmgsHLQx",
        "outputId": "b95d452d-c414-47ed-d173-cc691ec3d509"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YoygaagkZXr"
      },
      "source": [
        "# Install FastAI2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQIHL4dKjham"
      },
      "source": [
        "> Run the cell below to update the FastAi package in the node to version 2. Colab instances use the outdated version. <br /><br />\n",
        "> ⚠️ Make sure to restart the current runtime after the installation for changes to affect. Select 'Runtime' From the top menu and click on 'Restart Runtime'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE4ETrVnh7aN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebe541d-75f5-4ce5-934f-67c677b7d3c2"
      },
      "source": [
        "!pip install -Uq fastai"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 189 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxjOkBiuJ7ol"
      },
      "source": [
        "# Part 1: Sentiment Analysis (Text Classification)\n",
        "\n",
        "* Text Classification Examples\n",
        "  * Social Media Analysis\n",
        "  * Spam Detection\n",
        "  * Tag Enquiries (Sent to Different Departments)\n",
        "  * Categorize Articles, ...\n",
        "* Code-first Approach to Deep Learning\n",
        "* Focus on FastAI library.\n",
        " * Get near SOTA score with minimal code\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6VbeSF9dB85"
      },
      "source": [
        "# How to Feed Text to Neural Network?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl1YZPiJftue"
      },
      "source": [
        "> Comparing to Vision, there are a couple of extra steps to feed data to NN models. We have these steps to convert a word to integer values. <br /><br />\n",
        "> 1. Concatenate the dataset\n",
        "> 2. Tokenize\n",
        "> 3. Make a vacabulary (Numericalize)\n",
        "> 4. **Chose the Represenation!**\n",
        ">\n",
        "> Let's see an example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWCIpDkOnilt"
      },
      "source": [
        "## 1. Concatenate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJrf6vj18gtp"
      },
      "source": [
        "> To easily have access to all the words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1V18QfOdBiR"
      },
      "source": [
        "dataset = [\"She went to the stadium\", \"It's going to be legendary\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYCPPyTcfBbh"
      },
      "source": [
        "dataset_merged = \" \".join( dataset )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ywaZx1FIfKiG",
        "outputId": "560811f2-f5ac-4e51-d88c-46cde7afa36c"
      },
      "source": [
        "dataset_merged"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"She went to the stadium It's going to be legendary\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2i43dUCo92a"
      },
      "source": [
        "## 2. Tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU8TVf6P8nr0"
      },
      "source": [
        "> Convert words to tokens. There are different types of methods for tokenizing. Namely:\n",
        "  * Character Level: Consider each character as a Token. \n",
        "  * Word Level: Consider each word as a Token. This is the most basic tokenization method.\n",
        "  * Subword Level: In this method, we will break down the words like \"playing\" to \"play\"+\"ing\". It becomes the most popular method recently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rJc-yA3pAvx"
      },
      "source": [
        "<center> <img src=\"https://miro.medium.com/max/640/1*RcSo3UpBTorMI6YJvVizSg.jpeg\" /> </center>\n",
        "<center><small> Credit: <a href=\"https://nlpiation.medium.com/how-to-use-huggingfaces-transformers-pre-trained-tokenizers-e029e8d6d1fa\">NLPiation</a> </small></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN0iedxhveXp",
        "outputId": "4b9fdfb6-ad96-463a-87ea-7558138809dc"
      },
      "source": [
        "import numpy\n",
        "dataset_merged = numpy.array( dataset_merged.split(\" \") )\n",
        "\n",
        "print(dataset_merged)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['She' 'went' 'to' 'the' 'stadium' \"It's\" 'going' 'to' 'be' 'legendary']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B87xI7OE8bDq"
      },
      "source": [
        "## 3. Make Vacabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuiXsuextMIQ"
      },
      "source": [
        "> Make a vocabulary of unique tokens. Then, we can use the token index from the vocabulary as the token id."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrVtPQGUmj3W",
        "outputId": "2895faf0-3a4a-48ab-f738-24158c752674"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder   = LabelEncoder()\n",
        "label_encoder.fit( dataset_merged )\n",
        "\n",
        "print( \"Vocabs:\", label_encoder.classes_ )\n",
        "print( \"indexes:\", [i for i in range(0, 9)])\n",
        "print( \"Number of Words:\", len(label_encoder.classes_) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabs: [\"It's\" 'She' 'be' 'going' 'legendary' 'stadium' 'the' 'to' 'went']\n",
            "indexes: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "Number of Words: 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7IYjKBsgI_R"
      },
      "source": [
        "> ⚠️ It is not possible to make a vocabulary of all the available words in the document in real-world applications. We will only pick the most frequent words. There is always a special \"Unknown\" token to deal with Out Of Vocabulary (OOV) tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQRYptnTwQIj",
        "outputId": "517dbbee-7000-4e45-8e71-0f5925accdb4"
      },
      "source": [
        "encoded = label_encoder.fit_transform( dataset_merged )\n",
        "\n",
        "encoded = encoded.reshape(len(encoded), 1)\n",
        "print(encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1]\n",
            " [8]\n",
            " [7]\n",
            " [6]\n",
            " [5]\n",
            " [0]\n",
            " [3]\n",
            " [7]\n",
            " [2]\n",
            " [4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMEgv8EG8fNa"
      },
      "source": [
        "## 4. Representation: 1-hot Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGJ388AD-A7X"
      },
      "source": [
        "> Make a list with the same size as our vocabulary, where each index of the list represents one token. One list can only represent one token by putting 1 in its index and filling the other indexes with 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFBhZMGxt7le"
      },
      "source": [
        "It's|She|be|going|legendary|stadium|the|to|went|↓\n",
        "-|-|-|-|-|-|-|-|-|-\n",
        "0|0|0|0|0|0|0|0|0|-\n",
        "1|0|0|0|0|0|0|0|0|It's\n",
        "0|1|0|0|0|0|0|0|0|She\n",
        "0|0|1|0|0|0|0|0|0|be"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tWGuUaCwIzI",
        "outputId": "c00985c6-58db-49a7-bd15-7eef4d2c221e"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "onehot_encoded = onehot_encoder.fit_transform(encoded)\n",
        "print(onehot_encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI8spIkN8myJ"
      },
      "source": [
        "> One-hot encoding is not a good representation. Most of the indexes in the vector do not hold any meaningful information (0s), and the indexes that are 1s do not provide a measure of similarity! Keep in mind that a typical vocabulary in real-world applications might contain more than 60K tokens. (depending on the model size) It means to represent a token, we have 59,999 indexes filled with 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXKiSrCuCujT"
      },
      "source": [
        "## 4. Representation: What is Word2Vec?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4BgzUQmWQrO"
      },
      "source": [
        "<center> <img width=\"400\" src=\"https://raw.githubusercontent.com/AlaFalaki/workshop-materials/main/2021-practical-deep-learning/materials/word2vec.png\" /> </center>\n",
        "\n",
        "\n",
        "> Word2Vec [2] is a **self-supervised** algorithm (more about it on Language Models part) to create meaningful embedding for words. The pre-trained version of the model that trained on large corpus (like News datasets) is available for downloading. It try to predict the neighbor words (*w(t-2), w(t-1), w(t+1), w(t+2)*) given a *w(t)* word during training process. [Read More](https://jalammar.github.io/illustrated-word2vec/)<br />\n",
        "> Let's load the model and see how powerful it is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8bukQVUxu3F"
      },
      "source": [
        "### Load the pre-trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7knI56Ms-_Ad"
      },
      "source": [
        "> Downloading the Google's pretrained version on News datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw2yWxEudZVl",
        "outputId": "b2bbac30-afa5-4e12-e84e-857e43507d2f"
      },
      "source": [
        "!wget -P /content/sample_data/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-15 19:34:23--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.43.6\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.43.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘/content/sample_data/GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  46.1MB/s    in 48s     \n",
            "\n",
            "2021-07-15 19:35:11 (32.7 MB/s) - ‘/content/sample_data/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExK-CmfW_F3t"
      },
      "source": [
        "> We can load the model using the gensim library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCL98QuydZQo"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "pretrained_model = '/content/sample_data/GoogleNews-vectors-negative300.bin.gz'\n",
        "word_vectors = KeyedVectors.load_word2vec_format(pretrained_model, binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkYHDKtefs5j",
        "outputId": "b285d4c5-a153-4f05-df3b-53b17e7aac40"
      },
      "source": [
        "word_vectors['beautiful']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.01831055,  0.05566406, -0.01153564,  0.07275391,  0.15136719,\n",
              "       -0.06176758,  0.20605469, -0.15332031, -0.05908203,  0.22851562,\n",
              "       -0.06445312, -0.22851562, -0.09472656, -0.03344727,  0.24707031,\n",
              "        0.05541992, -0.00921631,  0.1328125 , -0.15429688,  0.08105469,\n",
              "       -0.07373047,  0.24316406,  0.12353516, -0.09277344,  0.08203125,\n",
              "        0.06494141,  0.15722656,  0.11279297, -0.0612793 , -0.296875  ,\n",
              "       -0.13378906,  0.234375  ,  0.09765625,  0.17773438,  0.06689453,\n",
              "       -0.27539062,  0.06445312, -0.13867188, -0.08886719,  0.171875  ,\n",
              "        0.07861328, -0.10058594,  0.23925781,  0.03808594,  0.18652344,\n",
              "       -0.11279297,  0.22558594,  0.10986328, -0.11865234,  0.02026367,\n",
              "        0.11376953,  0.09570312,  0.29492188,  0.08251953, -0.05444336,\n",
              "       -0.0090332 , -0.0625    , -0.17578125, -0.08154297,  0.01062012,\n",
              "       -0.04736328, -0.08544922, -0.19042969, -0.30273438,  0.07617188,\n",
              "        0.125     , -0.05932617,  0.03833008, -0.03564453,  0.2421875 ,\n",
              "        0.36132812,  0.04760742,  0.00631714, -0.03088379, -0.13964844,\n",
              "        0.22558594, -0.06298828, -0.02636719,  0.1171875 ,  0.33398438,\n",
              "       -0.07666016, -0.06689453,  0.04150391, -0.15136719, -0.22460938,\n",
              "        0.03320312, -0.15332031,  0.07128906,  0.16992188,  0.11572266,\n",
              "       -0.13085938,  0.12451172, -0.20410156,  0.04736328, -0.296875  ,\n",
              "       -0.17480469,  0.00872803, -0.04638672,  0.10791016, -0.203125  ,\n",
              "       -0.27539062,  0.2734375 ,  0.02563477, -0.11035156,  0.0625    ,\n",
              "        0.1953125 ,  0.16015625, -0.13769531, -0.09863281, -0.1953125 ,\n",
              "       -0.22851562,  0.25390625,  0.00915527, -0.03857422,  0.3984375 ,\n",
              "       -0.1796875 ,  0.03833008, -0.24804688,  0.03515625,  0.03881836,\n",
              "        0.03442383, -0.04101562,  0.20214844, -0.03015137, -0.09619141,\n",
              "        0.11669922, -0.06738281,  0.0625    ,  0.10742188,  0.25585938,\n",
              "       -0.21777344,  0.05639648, -0.0065918 ,  0.16113281,  0.11865234,\n",
              "       -0.03088379, -0.11572266,  0.02685547,  0.03100586,  0.09863281,\n",
              "        0.05883789,  0.00634766,  0.11914062,  0.07324219, -0.01586914,\n",
              "        0.18457031,  0.05322266,  0.19824219, -0.22363281, -0.25195312,\n",
              "        0.15039062,  0.22753906,  0.05737305,  0.16992188, -0.22558594,\n",
              "        0.06494141,  0.11914062, -0.06640625, -0.10449219, -0.07226562,\n",
              "       -0.16992188,  0.0625    ,  0.14648438,  0.27148438, -0.02172852,\n",
              "       -0.12695312,  0.18457031, -0.27539062, -0.36523438, -0.03491211,\n",
              "       -0.18554688,  0.23828125, -0.13867188,  0.00296021,  0.04272461,\n",
              "        0.13867188,  0.12207031,  0.05957031, -0.22167969, -0.18945312,\n",
              "       -0.23242188, -0.28710938, -0.00866699, -0.16113281, -0.24316406,\n",
              "        0.05712891, -0.06982422,  0.00053406, -0.10302734, -0.13378906,\n",
              "       -0.16113281,  0.11621094,  0.31640625, -0.02697754, -0.01574707,\n",
              "        0.11425781, -0.04174805,  0.05908203,  0.02661133, -0.08642578,\n",
              "        0.140625  ,  0.09228516, -0.25195312, -0.31445312, -0.05688477,\n",
              "        0.01031494,  0.0234375 , -0.02331543, -0.08056641,  0.01269531,\n",
              "       -0.34179688,  0.17285156, -0.16015625,  0.07763672, -0.03088379,\n",
              "        0.11962891,  0.11767578,  0.20117188, -0.01940918,  0.02172852,\n",
              "        0.23046875,  0.28125   , -0.17675781,  0.02978516,  0.08740234,\n",
              "       -0.06176758,  0.00939941, -0.09277344, -0.203125  ,  0.13085938,\n",
              "       -0.13671875, -0.00500488, -0.04296875,  0.12988281,  0.3515625 ,\n",
              "        0.0402832 , -0.12988281, -0.03173828,  0.28515625,  0.18261719,\n",
              "        0.13867188, -0.16503906, -0.26171875, -0.04345703,  0.0100708 ,\n",
              "        0.08740234,  0.00421143, -0.1328125 , -0.17578125, -0.04321289,\n",
              "       -0.015625  ,  0.16894531,  0.25      ,  0.37109375,  0.19921875,\n",
              "       -0.36132812, -0.10302734, -0.20800781, -0.20117188, -0.01519775,\n",
              "       -0.12207031, -0.12011719, -0.07421875, -0.04345703,  0.14160156,\n",
              "        0.15527344, -0.03027344, -0.09326172, -0.04589844,  0.16796875,\n",
              "       -0.03027344,  0.09179688, -0.10058594,  0.20703125,  0.11376953,\n",
              "       -0.12402344,  0.04003906,  0.06933594, -0.34570312,  0.03881836,\n",
              "        0.16210938,  0.05761719, -0.12792969, -0.05810547,  0.03857422,\n",
              "       -0.11328125, -0.1953125 , -0.28125   , -0.13183594,  0.15722656,\n",
              "       -0.09765625,  0.09619141, -0.09960938, -0.00285339, -0.03637695,\n",
              "        0.15429688,  0.06152344, -0.34570312,  0.11083984,  0.03344727],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTf7zYV9_KgR"
      },
      "source": [
        "> As you can see, each token in the model will be represented with 300 positive/negative numbers because it is the model size. These vectors hold a lot of information in their 300 dimensions. We can easily find close vectors with methods like cosine similarity. However, it is built-in in the gensim library. Let's see some examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9frzz6ve3pI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2f0649c-6157-4274-9ceb-f156c19fdd44"
      },
      "source": [
        "word_vectors.most_similar(\"beautiful\", topn=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gorgeous', 0.8353004455566406),\n",
              " ('lovely', 0.810693621635437),\n",
              " ('stunningly_beautiful', 0.7329413890838623),\n",
              " ('breathtakingly_beautiful', 0.7231341004371643),\n",
              " ('wonderful', 0.6854087114334106),\n",
              " ('fabulous', 0.6700063943862915),\n",
              " ('loveliest', 0.6612576246261597),\n",
              " ('prettiest', 0.6595001816749573),\n",
              " ('beatiful', 0.6593326330184937),\n",
              " ('magnificent', 0.6591402292251587)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnMxmmLfriKQ"
      },
      "source": [
        "> It can also understand the deeper relationship between the tokens. For example, the connection between being a king and a man to being a queen and a woman. Or an adjective and comparative adjective. Lastly, it can find out the odd token from a list of tokens.<br /><br />\n",
        "vector['woman'] + vector['king'] - vecotr['man'] = ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHiS1D6tdZML",
        "outputId": "59a3b3ea-a69f-4cf4-87ee-8f10ea9d1705"
      },
      "source": [
        "word_vectors.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7118192911148071)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsIE5mM6dY6a",
        "outputId": "4132eb02-4e7a-4177-b06a-6a07c3fb468f"
      },
      "source": [
        "word_vectors.most_similar(positive=['small', 'smaller'], negative=['large'], topn=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('larger', 0.595083475112915)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "PDpwDrLoGicD",
        "outputId": "b421d87e-3dc1-4eab-b34d-f26971a402c9"
      },
      "source": [
        "word_vectors.doesnt_match(\"banana apple orange sausage\".split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sausage'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "MI3jkApwGqAF",
        "outputId": "627f434e-1038-4e3a-82a2-684ebcfed022"
      },
      "source": [
        "word_vectors.doesnt_match(\"vanilla chocolate cinnamon dish\".split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dish'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMuSXvY6BEvN"
      },
      "source": [
        "> You can train your own Word2Vec model based on your custom dataset. It will result in a model less generalized, but more fitted to your own dataset. Pleaes refer to my last year (2021) workshop [notebooks](https://github.com/AlaFalaki/workshop-materials/tree/main/2021-practical-deep-learning) if you are interested in learning it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjsoMWM-IrKc"
      },
      "source": [
        "# Language Models + Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PACU24_5IxSF"
      },
      "source": [
        "> Word2Vec was one of the first examples of using transfer learning in Natural Language Processing. And a very powerful one as well! But, the problem is, it always generates the same vector for a word, no matter what the context is. The context matters in NLP! A lot!<br /><br />\n",
        "We would like to have a representation that generates different vectors for one token based on its context. For example, the representation for the word \"metal\" should be different when it is used to describe a \"metal object\" comparing to a \"music genre\".<br /><br />\n",
        "Language models are also considered to be **self-supervised**, meaning we can train them with any corpus without providing the labels. These models can pick a sentence from the corpus and use the shifted sentence by one token as the label. We do not need to put additional effort into providing the labels (You will see an example of it in the Language Model Dataloader section), and because of it, they are powerful tools to learn representation from the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgEMJGxMOYs6"
      },
      "source": [
        "<center> <img src=\"https://raw.githubusercontent.com/AlaFalaki/workshop-materials/main/2021-practical-deep-learning/materials/iamahugemetalfan.jpeg\" width=\"500\" />\n",
        "\n",
        "<small>Credit: not found.</small>\n",
        " </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFSsEedl4dFM"
      },
      "source": [
        "> So, We feed them a text as a starting point; they try to predict the next word! (The newly predicted word will be concatenated with the input, and the model attempts to predict a new token based on the new input. It is a loop until we reach a limit)\n",
        "\n",
        "<center> <img width=\"500\" src=\"https://raw.githubusercontent.com/AlaFalaki/workshop-materials/main/2021-practical-deep-learning/materials/lm.png\" /> <center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MevZucrAy9g"
      },
      "source": [
        "> As it turned out, they learn about language structure through this process. Let's see how they work; we start by importing the [FastAI](https://github.com/fastai/fastai) library and load the Yelp dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oN75flV0y8L"
      },
      "source": [
        "from fastai.text.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oiUPvvSFGVE"
      },
      "source": [
        "import torch, fastai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpaG2clsFHlI",
        "outputId": "9557496d-6de5-4799-c111-8a9ecd1fad5a"
      },
      "source": [
        "torch.__version__, fastai.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.10.0+cu111', '2.5.3')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U1fS_STz9bi"
      },
      "source": [
        "## Load the LM Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX7_5lihWSWW"
      },
      "source": [
        "> First, we need to download the dataset. You can either download the Yelp reviews dataset from the internet and upload it here or use the FastAi's URLs object+untar_data function, which downloads and uncompress the dataset for us. It will return the path on which the dataset is saved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "lWk1H5PusT_M",
        "outputId": "715a6cea-0569-444a-b8de-b232ce3cc7fc"
      },
      "source": [
        "path = untar_data(URLs.YELP_REVIEWS_POLARITY)\n",
        "path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='166379520' class='' max='166373201' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [166379520/166373201 00:02<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/root/.fastai/data/yelp_review_polarity_csv')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apk4vACUW6aV"
      },
      "source": [
        "> Since our dataset is a CSV file. The best option to open it is to use the Pandas Dataframe object. It is a very flexible datatype to deal with CSV files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "dqBgNybOuBuz",
        "outputId": "cff035b6-5d27-414a-bf0b-8c042e5662a0"
      },
      "source": [
        "df = pd.read_csv(path/\"train.csv\", header=0, names=['label', 'text'])\n",
        "df = df[0:len( df )//4] # Just to train faster, comment for full training.\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a6c31a4e-795c-43ae-bc9c-6236b2c470be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I don't know what Dr. Goldberg was like before  moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>I'm writing this review to give you a heads up before you see this Doctor. The office staff and administration are very unprofessional. I left a message with multiple people regarding my bill, and no one ever called me back. I had to hound them to get an answer about my bill. \\n\\nSecond, and most important, make sure your insurance is going to cover Dr. Goldberg's visits and blood work. He recommended to me that I get a physical, and he knew I was a student because I told him. I got the physical done. Later, I found out my health insurance doesn't pay for preventative visits. I received an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>All the food is great here. But the best thing they have is their wings. Their wings are simply fantastic!!  The \\\"Wet Cajun\\\" are by the best &amp; most popular.  I also like the seasoned salt wings.  Wing Night is Monday &amp; Wednesday night, $0.75 whole wings!\\n\\nThe dining area is nice. Very family friendly! The bar is very nice is well.  This place is truly a Yinzer's dream!!  \\\"Pittsburgh Dad\\\" would love this place n'at!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Wing sauce is like water. Pretty much a lot of butter and some hot sauce (franks red hot maybe).  The whole wings are good size and crispy, but for $1 a wing the sauce could be better. The hot and extra hot are about the same flavor/heat.  The fish sandwich is good and is a large portion, sides are decent.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6c31a4e-795c-43ae-bc9c-6236b2c470be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6c31a4e-795c-43ae-bc9c-6236b2c470be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6c31a4e-795c-43ae-bc9c-6236b2c470be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   label                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     text\n",
              "0      2                                                                                                          Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.\n",
              "1      1  I don't know what Dr. Goldberg was like before  moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you c...\n",
              "2      1  I'm writing this review to give you a heads up before you see this Doctor. The office staff and administration are very unprofessional. I left a message with multiple people regarding my bill, and no one ever called me back. I had to hound them to get an answer about my bill. \\n\\nSecond, and most important, make sure your insurance is going to cover Dr. Goldberg's visits and blood work. He recommended to me that I get a physical, and he knew I was a student because I told him. I got the physical done. Later, I found out my health insurance doesn't pay for preventative visits. I received an...\n",
              "3      2                                                                                                                                                                                All the food is great here. But the best thing they have is their wings. Their wings are simply fantastic!!  The \\\"Wet Cajun\\\" are by the best & most popular.  I also like the seasoned salt wings.  Wing Night is Monday & Wednesday night, $0.75 whole wings!\\n\\nThe dining area is nice. Very family friendly! The bar is very nice is well.  This place is truly a Yinzer's dream!!  \\\"Pittsburgh Dad\\\" would love this place n'at!!\n",
              "4      1                                                                                                                                                                                                                                                                                                      Wing sauce is like water. Pretty much a lot of butter and some hot sauce (franks red hot maybe).  The whole wings are good size and crispy, but for $1 a wing the sauce could be better. The hot and extra hot are about the same flavor/heat.  The fish sandwich is good and is a large portion, sides are decent."
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkniTsuUXJia"
      },
      "source": [
        "> Now that we have the data loaded in a dataframe, we can use the from_df function from the TextDataLoader class. We should pass the text and label columns, also notice the is_lm flag is True in this example. (Because we want to load the dataset for language model) It means instead of loading the text and label in each row, it will load text and the shifted text by one token. This way model learns what token it should predict next. (Just compare the left/right texts in the example below)<br /><br />\n",
        "FastAi Dataloader will handle tokenization, splitting data to train/validation set, and also adds some special tokens like xxbos (for marking the beginning of the sentence), xxmaj (meaning the next character after it was uppercased), and xxunk (which replaces the tokens that are not in the vocabulary), ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "i-3mOdNMuY4b",
        "outputId": "2d55d757-6a88-4f44-fb17-9d7695e5200f"
      },
      "source": [
        "dls = TextDataLoaders.from_df(df, text_col='text', label_col='label', bs=64, is_lm=True)\n",
        "dls.show_batch(max_n=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj been waiting 40 min for 1 xxmaj sirloin xxmaj steak . .. at lunch … they are not busy … .looks good inside .. but my wife and i will not be returning . xxmaj sad for a beautiful place … customer service is poor xxbos i would first like to say that i woke up with my family at xxunk to eat breakfast at xxmaj chin xxmaj chin 's</td>\n",
              "      <td>xxmaj been waiting 40 min for 1 xxmaj sirloin xxmaj steak . .. at lunch … they are not busy … .looks good inside .. but my wife and i will not be returning . xxmaj sad for a beautiful place … customer service is poor xxbos i would first like to say that i woke up with my family at xxunk to eat breakfast at xxmaj chin xxmaj chin 's breakfast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>of my favorite places for take out . xxmaj they have a take out curb - side option which is great . xxmaj the one time we did dine in , the service was great . xxmaj the booths that we sat at was a bit dusty and dirty , but nevertheless , we still order take out from this place quite often . xxbos xxmaj if you 're gon na be</td>\n",
              "      <td>my favorite places for take out . xxmaj they have a take out curb - side option which is great . xxmaj the one time we did dine in , the service was great . xxmaj the booths that we sat at was a bit dusty and dirty , but nevertheless , we still order take out from this place quite often . xxbos xxmaj if you 're gon na be one</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgyG92syaQJB"
      },
      "source": [
        "> This process can take some time depends on the dataset you are using. If this is the case, you can use torch.save(), and torch.load() to respectively save and load the dataloader into a pickle file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK4dBrHLGdnV"
      },
      "source": [
        "# torch.save(dls, \"./lm_dls.pkl\")\n",
        "# dls = torch.load(\"./lm_dls.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8v49lrr0m6y"
      },
      "source": [
        "## Langugae Model + Fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsOhFZhQ1Z7A"
      },
      "source": [
        "> We can call the language_model_learner function to load a pre-trained language model called ULMFiT [3] (called AWD_LSTM in FastAi for some reason) trained on a large corpus. (Wikipedia-103) We can fine-tune it on any dataset to predict sentences with a different style.<br /><br />\n",
        "This architecture's language model (image a, b) is consists of an encoder (the first 4 layers) that is made of an embedding layer + 3 LSTM layers and a prediction head (which is a softmax layer that predicts the next word). When we want to use this model for classification (image c), we will remove the softmax head and use a Classification head (a linear layer) on top of the encoder.\n",
        "\n",
        "<center> <img width=\"800\" src=\"https://raw.githubusercontent.com/AlaFalaki/workshop-materials/main/2021-practical-deep-learning/materials/ulmfit-architecture.png\" /> </center>\n",
        "<center> <small>credit: ULMFiT paper [3]</small> </center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p97ewmoXulY6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "86e84ae1-97da-490e-ac30-955b33d09fe1"
      },
      "source": [
        "learn = language_model_learner(dls, AWD_LSTM, metrics=accuracy).to_fp16()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='105070592' class='' max='105067061' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [105070592/105067061 00:01<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui1sbmfAb9J2"
      },
      "source": [
        "> Let's try it to complete a sequence that starts with \"my experience\" with 30 words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "LxUpFJ26xviJ",
        "outputId": "04b8e5ee-df3d-4303-da48-f65d7dfd001d"
      },
      "source": [
        "TEXT  = \"my experience\"\n",
        "WORDS = 30\n",
        "\n",
        "learn.predict(TEXT, WORDS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'my experience routine screening muzzle grams of restraunt solution and DNA testing and detection screening , and a takamatsu security accident being considered in Australia , cardamom u00e9es for use'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DnLoZXJfUqG"
      },
      "source": [
        "> As you can see, it did not perform well. The sentences don't mean anything. It is because I asked it to complete a sequence it never saw before. You do not see a sentence started with \"my experience\" in the Wikipedia corpus (which this model is pre-trained on). Let's try fine-tuning it for our Yelp review dataset. It hopefully adapts the dataset style.<br /><br />\n",
        "To do this, we can call the **fine_tune()** function. It will first freeze the model's encoder (what is the encoder?) and train the head (either token prediction, or classification head) for one epoch, then reduce the learning rate to half and unfreeze the whole model and train it for 2 epochs. **It will use a lower learning rate to adjust the weights with respect to the new dataset, not to forget everything from before.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "t_15g0pC0AeU",
        "outputId": "140e3ea6-dd24-4d49-9080-618100ed9221"
      },
      "source": [
        "learn.fine_tune(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.216443</td>\n",
              "      <td>3.939138</td>\n",
              "      <td>0.278133</td>\n",
              "      <td>17:33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.961106</td>\n",
              "      <td>3.737998</td>\n",
              "      <td>0.296847</td>\n",
              "      <td>18:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.893233</td>\n",
              "      <td>3.690898</td>\n",
              "      <td>0.301515</td>\n",
              "      <td>18:53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3eMhyha2Ht1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1da54259-3661-49d7-bf91-5bf8cebad300"
      },
      "source": [
        "TEXT  = \"my experience\"\n",
        "WORDS = 30\n",
        "\n",
        "learn.predict(TEXT, WORDS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'my experience at this place was mediocre and definitely not a good price . i def takes it here some time , plus every time we visited , left bad experience .'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOtU9wXGUEM6"
      },
      "source": [
        "learn.save_encoder('encoder_finetuned')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v39UzArgpq1"
      },
      "source": [
        "> Obviously, the model actually learned how to generate text with the same style as the Yelp review dataset. This is the reason why we do fine-tune before using a pre-trained model on a downstream task. We just need to save the encoder part of the language model (responsible for making a representation from the data) to use it later in our classification model.\n",
        "\n",
        "> ⚠️ If you want to practice, a cool idea is to scrape tweets from people with lots of tweets and fine-tune the model to generate tweets with their writing style."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOmFTci8ul4o"
      },
      "source": [
        "## Classification model + Fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSiV4wG3hLPL"
      },
      "source": [
        "> The next step is to fine-tune the classification model. Again, the first step is to load the data in the appropriate format. We use the same from_df function but without the is_lm flag. You can see the difference below.\n",
        "<br /><br />\n",
        "Now we have the review with its label. The format we need to train a classification model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "-DwxC1kIrISB",
        "outputId": "135355db-cfb3-4273-b7f9-8238b8f46ead"
      },
      "source": [
        "dls = TextDataLoaders.from_df(df, text_col='text', label_col='label', seed=42)\n",
        "dls.show_batch(max_n=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos a xxup note xxup to xxup the xxup owner : \\n xxmaj your employee , the scrawny , balding man , should be fired . \\n xxmaj he was yelling at me and saying extremely rude things instead of fixing the nails to make the customer happy . xxmaj i 've never been treated this way by any company that xxmaj i 've ever done business with . i urge you to take a few moments to read about what happened from the customer 's point of view , as xxmaj i 'm sure that you may hear about it but from a different light that is favorable to the scrawny , balding man . \\n\\n xxup my xxup review : xxmaj they should n't even get xxup one xxup star . xxmaj the scrawny man with the receding hair that works there is the ultimate cause of this</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxbos xxmaj this is an extremely late review because i never had the time to finish it ( roughly 4.5 months late ) . \\n\\n xxmaj i 'll start by saying , \" wow . \" \" wow , what a seriously xxup revolting , xxup nasty , xxup disgusting , and xxup unsanitary place this is . \" i honestly do not understand how the public can tolerate such a dirty place , and sit down , and eat here without complaining at least once . xxmaj but , then again , i know why . xxmaj it 's their name , xxmaj saigon xxmaj fragrance ( in xxmaj english that is ) . xxmaj this place gets a straight out xxup f- \\n\\n i grade xxmaj vietnamese restaurants based on these criteria : 1 ) cleanliness , 2 ) freshness / smell , 3 ) taste / appearance</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xxbos xxmaj i 've been taking my xxup bmw and xxmaj nissan here for about 3 years . xxmaj in the past year , business seems to have gone up to the point that they xxup can not xxup maintain xxup previous xxup levels xxup of xxup good xxup old xxup fashioned \" mom xxup and xxup pop \" xxup customer xxup service . xxmaj maybe the perfect 5 star rating here has something to do with that , causing business to explode . xxmaj however , when this happens a business either expands , or customer service declines . xxmaj precision imports does not seem to desire expansion , and their customer service has become inconsistent and disorganized . \\n\\n xxmaj trust is vital with your mechanic , and xxmaj frank / xxmaj al broke trust with me in a few areas . i trusted them up until the</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxuxLldDtYms"
      },
      "source": [
        "learn = text_classifier_learner(dls, AWD_LSTM, metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aatLMSWMh6HA"
      },
      "source": [
        "> After loading the model architecture (encoder+classification head), we need to load our fine-tuned encoder from the previous step. And then repeat the same two-step fine-tuning procedure as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T1xHyovP9FY"
      },
      "source": [
        "learn = learn.load_encoder('encoder_finetuned')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "4Iz9BuvkUNU4",
        "outputId": "9f82c1b5-8122-4bfe-f7b5-a636265e23eb"
      },
      "source": [
        "learn.fine_tune(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.266396</td>\n",
              "      <td>0.196749</td>\n",
              "      <td>0.920533</td>\n",
              "      <td>06:39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.179773</td>\n",
              "      <td>0.139529</td>\n",
              "      <td>0.944498</td>\n",
              "      <td>15:19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.148842</td>\n",
              "      <td>0.130906</td>\n",
              "      <td>0.949105</td>\n",
              "      <td>15:20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Tm90atMjos4"
      },
      "source": [
        "> After fine-tuning, we reach 94.9% accuracy. It's not bad!<br /><br />\n",
        "Now that we have a working model. It is easy to save it or use it for predicting a sample sequence. In the second example, I used the combination of \"not\"+\"good\" to see if it understand the relationship between the words. As it turns out, it did. (Label 2 means a positive review, while label 1 means negative)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz51UbkOQCgU"
      },
      "source": [
        "learn.export(\"nlp_finetuned_cls\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKgn1jNIMplp"
      },
      "source": [
        "# learn.load_learner(\"nlp_finetuned_cls\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "OUGr9naMeKEJ",
        "outputId": "643b6349-608d-4643-ccbb-78fb821fd33e"
      },
      "source": [
        "print( learn.predict(\"I really like this restaurant.\") )\n",
        "print( learn.predict(\"Not so good restaurant.\") )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('2', TensorText(1), TensorText([0.0438, 0.9562]))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('1', TensorText(0), TensorText([0.9976, 0.0024]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xBjMcRVAOuq"
      },
      "source": [
        "## Fine-Tune Just the Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kkq_nnalQ6S3"
      },
      "source": [
        "> Let's see what happens if we skip fine-tuning the language model's encoder first and just fine-tune the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIhe8nyahizS"
      },
      "source": [
        "learn = text_classifier_learner(dls, AWD_LSTM, metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "v720Qinrhk_S",
        "outputId": "655d1d9a-6f3d-48fc-9a34-889edcc04e68"
      },
      "source": [
        "learn.fine_tune(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.399679</td>\n",
              "      <td>0.309529</td>\n",
              "      <td>0.871924</td>\n",
              "      <td>06:36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.232444</td>\n",
              "      <td>0.176336</td>\n",
              "      <td>0.929533</td>\n",
              "      <td>15:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.200871</td>\n",
              "      <td>0.163014</td>\n",
              "      <td>0.935105</td>\n",
              "      <td>15:21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY1ds10QRFs3"
      },
      "source": [
        "> There is a 1.5% difference. It might not look much, but it is a big deal if you are in a competition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Klsn3WcYXqky"
      },
      "source": [
        "## Let's look under the hood"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRyqSYwtu4Fn"
      },
      "source": [
        "> We will look at a basic implementation of a simple text classifier. You will see the model's implementation with PyTorch and learn how to find the best learning rate and do the training loop using FastAi. This part shows how we can use FastAi to take care of data and the training loop while we only focus on implementing the model. It is convenient for doing experiments to focus on just one specific part of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBI00evzdkrY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "4d7e72bf-a4c2-4ad8-b8cb-598522adf362"
      },
      "source": [
        "dls = TextDataLoaders.from_df(df, text_col='text', label_col='label', seed=42)\n",
        "dls.show_batch(max_n=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj oh , xxup t.i . xxmaj you should be xxup ashamed to even call this a \" buffet . \" \\n\\n xxmaj we got comped , so we checked it out , and decided \" what the heck . \" xxmaj unfortunately , we 'd checked it out at late breakfast time , and actually did the whole \" eating \" part at dinner . xxmaj breakfast , if small in selection , at least looked decent . xxmaj dinner ? \\n\\n xxmaj oh . xxmaj em . xxmaj gee . \\n\\n xxmaj first of all , i really hope xxup every person ( all 6 of them ) at the buffet that evening were also xxmaj comped . xxmaj because seriously ? xxmaj if xxmaj i 'd paid $ 22 for that \" selection \" of foods , xxmaj i 'd be calling the xxmaj better xxmaj</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxbos xxrep 9 * xxup do xxup not xxup stay xxup here . xxrep 5 * xxmaj quality and service are now a xxup zero . xxup not a xxup family place xxup at xxup all . \\n\\n xxmaj seriously went down in quality since our last visit . xxmaj we stayed xxmaj may 22 - xxmaj may 27 , 2014 and our experience was horrible . xxmaj this property is in serious finical trouble that staff has been cut &amp; reflected in the poor overall impression of this once nice property . \\n\\n 1 ) xxmaj prior to arriving , i called to request a room upstairs , easy in &amp; out , and a microwave . xxmaj maria , the clerk , told me all rooms have microwaves and assured me i do nt need to ask . \\n\\n 2 ) xxup ck - in . xxmaj the</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xxbos xxmaj it gets a xxup meh from me . xxmaj nothing spectacular here in my opinion , but it 's ok if you want to eat safe seafood . i think i may be a bit bias on this though because i am from xxmaj hawaii and xxmaj i 've had my fair share of \" chicken of the xxmaj sea \" , and the quality of the stuff from xxmaj red xxmaj lobster just does n't even compare with what you can catch with your own bare hands from what basically used to be my own backyard . \\n\\n i remember the days , parties with platters upon platters of raw , fresh sashimi ( oh how i miss you hot mustard &amp; shoyu ! ) , places quality sushi , and the lovely aroma of fish tempura with a squeeze of lemon , some tartar sauce and</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZeSxfW6lCG6"
      },
      "source": [
        "> To implement a PyTorch model, you need to make a class that inherits from the PyTorch Module component. It must have two main, the __init__ function, which we will use to define our model's layers and parameters, and the __forward__ function that accepts an input and determine the flow of the data between the layers. We will talk about each layer in Part 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaYHKUNgea7g"
      },
      "source": [
        "class Classifier(Module):\n",
        "  def __init__(self, vocab_size):\n",
        "    self.number_of_layers = 3\n",
        "    self.number_of_targets = 2\n",
        "    self.hidden_size = 300\n",
        "\n",
        "    self.emb        = nn.Embedding(vocab_size, self.hidden_size)\n",
        "    self.encoder    = nn.LSTM(self.hidden_size, self.hidden_size, self.number_of_layers, batch_first=True)\n",
        "    self.classifier  = nn.Linear(self.hidden_size, self.number_of_targets)\n",
        "\n",
        "  def forward(self, inp):\n",
        "\n",
        "    inp_embded = self.emb(inp)\n",
        "    _, hidden_state = self.encoder(inp_embded)\n",
        "\n",
        "    # The line below is just to fix a weird bug to integrates\n",
        "    # FastAI and PyTorch. Hopefully it will be fixed soon, but\n",
        "    # we should use this line for now!\n",
        "    # You can remove the line and try to train the model once,\n",
        "    # If it worked, good, the bug is fixed. If not, leave it!\n",
        "    hidden_state = torch.Tensor(hidden_state[0][-1].cpu().float()).float().to(device)\n",
        "    \n",
        "    cls = self.classifier( hidden_state[0][-1] )\n",
        "    \n",
        "    return cls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7_QrlyHl148"
      },
      "source": [
        "> The FastAi __Learner__ function will accept a dataloader and a model architecture for training. You can also pass the loss function and an evaluation metric like accuracy after having the learner object. We can use the __lr_find__ function to find the most optimal learning rate for training. Then use the __fit_one_cycle__ for training the model from scratch. (We no longer fine-tune because there are no pre-trained encoder)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrHSGzxCdldb"
      },
      "source": [
        "model = Classifier(len(dls.vocab[0]))\n",
        "\n",
        "learn = Learner(dls, model,\n",
        "                    loss_func=LabelSmoothingCrossEntropy(), metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "KqUnY2ysjAsp",
        "outputId": "61f14f06-dab9-41be-bb01-eae79cfe5522"
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(valley=tensor(0.0017))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz_QyCEydlQ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "4b694b1d-5d3e-4ffc-f040-eef7606aaccf"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.298209</td>\n",
              "      <td>0.300382</td>\n",
              "      <td>0.937374</td>\n",
              "      <td>07:48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADPoMA8oSUbs"
      },
      "source": [
        "> We got a 93.7% accuracy out of our custom model, which only trained for one epoch from scratch. It is actually really good.\n",
        "\n",
        "> Let's have a break. We will look closely at some components in Part 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3gJe2ro7xlS"
      },
      "source": [
        "# Workshop Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmURyIYw7zca"
      },
      "source": [
        "> Go to [NLP Part 2](https://colab.research.google.com/github/AlaFalaki/workshop-materials/blob/main/2022-practical-deep-learning/02-NLP_Part2.ipynb) notebook. (PyTorch vs. FastAi)<br /><br />\n",
        "> Also, this [Github Repository](https://github.com/AlaFalaki/workshop-materials/tree/main/2022-practical-deep-learning) contains all the notebooks and materials presented in this workshop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs7jBv5W-Bs8"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoTxaIrz-D-U"
      },
      "source": [
        "1. *Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781.*\n",
        "\n",
        "2. *Maas, A., Daly, R., Pham, P., Huang, D., Ng, A., & Potts, C. (2011). Learning Word Vectors for Sentiment Analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (pp. 142–150). Association for Computational Linguistics.*\n",
        "\n",
        "3. *Howard, J., & Ruder, S. (2018). Universal language model fine-tuning for text classification. arXiv preprint arXiv:1801.06146.*"
      ]
    }
  ]
}